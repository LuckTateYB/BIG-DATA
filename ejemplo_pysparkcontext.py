# -*- coding: utf-8 -*-
"""ejemplo_pysparkContext

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14qU7zVKy1U5PEWuw7I_-EmGONnxsjN_n
"""

pip install pyspark

import csv

from pyspark.context import SparkContext

sc = SparkContext('local', 'test')

csv_file = "/content/sample_data/Online Sales Data.csv"

rdd_csv = sc.textFile(csv_file)

rdd= rdd_csv.map(lambda line: next(csv.reader([line])))
rdd.collect()

filtered = rdd.filter(lambda x: x[0] != "Units Sold") # Filtrar encabezado
filtered.collect()

flatMapped = rdd.flatMap(lambda x: x) # Aplanar
flatMapped.collect()